# IBM HR Analytics
Project for BU.330.780.53
### 1)	Business Understanding
Nowadays, many companies, including IBM, are facing a high attrition rate issue. Attrition in business means a gradual reduction in employees who retire or resign and are not replaced. A high attrition rate means that companies cannot retain much of their workforce, and it will hurt the remaining staff because it results in an increase in their workload. Besides, this problem may limit promotional opportunities and movement in the firm and causing more attrition in the future. Furthermore, companies spend a significant amount of resources and capital to train new employees, and a high attrition rate makes it difficult for companies to stick to business plans since their employees always change. All these facts could lead to a failure of a firm. Therefore, it is important to keep the attrition rate low. To help solve this business problem, we build three models, classification tree, support vector machine, and gradient boosting machine based on the given dataset. These models will predict whether a potential employee will quit the company. The prediction results can help companies to evaluate their employees and work environment and reduce the attrition rate in the future.
Our target variable is attrition. Our models will predict the probability of attrition of employees based on the other important independent variables. The AUC of each model is not very high, but it is not bad as well and does work for our business objective. The following paragraphs will talk about our project step by step. We first did exploratory data analysis and some data visualization will be presented in the report. The next one is the modeling which is based on our analyzed data. Three models are built in this section and each of them has its advantages. Evaluation is followed by modeling. Several evaluation methods like cross validation are applied to fine tune our models to achieve better performance. Finally, we discussed how our results will be deployed in improving employee retention.
### 2)	Data visualization
This fictional dataset is from IBM HR department. IBM has spent a significant amount of time and resources training new employees, but it is still hard for the company to find a better way to retain employees. Our dataset contains a lot of useful and important features. There are 1470 instances for individual employees. In total, there are more than 35 features, and a binary target variable. Among 35 different features, there are some interesting features, such as work-life balance, business travel or not, and job involvement. However, there are some less useful features that we decided to not include, such as employee counts, employee number, etc.  
It is difficult to come up with a perfect model to address our problem. Thus, we make a pair-wise correlation matrix (see exhibit 1) between all features and use that as a guide map for us to find possible relationships. In this map, there are some intense color blocks, which indicate that 2 features are highly correlated, and then we move on with those indicators and apply them in our later steps.

Interesting findings:
Business Travel has always been a hot topic. Everyone likes to travel and let the company take care of the bill, right? According to our dataset, it is not the case with IBM employees. We have not seen a significant relationship between attrition and business travel. Base on the graph, both categories behave almost the same. Whether or not the job provides business travel or not, people are equally to leave the company. We conclude that business travel might not be an important factor to determine attrition rate in our project. However, it’s an interesting finding for us.
A lot of people argue that work life balance and distance from home might be important factors to determine the attrition rate. However, according to our data, we haven’t seen any of that. As the graph indicated whether or not an employee leaves, both features have the same distribution, which indicate that both features might not provide much details and information for our later analysis. (*More graphs are located in the appendix section.)

### 3)	Modeling 
Before using any models, we need to clean the data in a few steps. We first delete columns that provide little informational value to our analysis. We delete variables `EmployeeCount`, `Over18`, and `StandardHours`, because each have only one value. We also delete `EmployeeNumber` because it is irrelevant when predicting the attrition. We also observe that the class distribution is imbalanced, so we provide the option of oversampling (or not) using Synthetic Minority Oversampling Technique (SMOTE). We cannot under-sample because the dataset is very small. Without making the two classes roughly the same size, classification is biased in favor of the majority class. We also encode the factors of two classes into binary type (1 and 0), and factors of three or more classes into one-hot type. We leave the ordinal variables as they are. As the last step of the data cleaning process, we normalize all variables to a scale between 0 and 1. Normalization is important especially for SVM (but much more trivial for tree-based models). Without normalization, variables with larger values will exert undue influence and bias when fitting the model. 

The data present themselves as a supervised classification problem. We therefore use three popular models in this context: classification tree (CT), support vector machine (SVM), and gradient boosting machine (GBM). For each model, we tune the hyper-parameters using a 5-fold cross validation. The tuning and cross-validation are conducted over the training set, and we test the best model over the testing set. CT is a tree-based models and is extremely versatile with different data types. They are suitable for this particular dataset for two main reasons. First, the dataset has numerous categorical variables, which do not need encoding (creating dummy variables) if fitted to the tree-based models. Second, it is convenient to interpret categorical variables, such as by plotting the decision tree. Through a decision tree, we can easily visualize which variables are more useful in partitioning and determining employee attrition. Some disadvantages of CT include instability, meaning that a small change in the data can lead to a significant change in the structure of the optimal CT. We can limit this downside by using cross-validation. Another disadvantage is that CT can easily overfit. This can be mitigated by cross-validation, pruning, limiting the largest number of nodes / depths. For the tuning process, we set the maximum depth of the tree to be five so that it is not overfitting. We also pruned the tree based on the smallest relative error in the Complexity Parameter (CP) table. 

The most obvious benefit of SVM is its effectiveness in dealing with high dimensional data. Our original dataset has more than 30 variables and more than 50 after encoding the categorical variables. As a result, SVM is extremely suited for the task. However, SVM underperforms when the data set has more noise. In our case, target classes are overlapping and the decision boundaries not clear-cut. The imbalance of classes makes the situation worse. For our testing set, SVM classifies all classes as negative, when in fact 47 out of the 293 cases are positive (attrition). For SVM’s hyper-parameter tuning, we tuned three parameters: gamma, cost, and kernel. The gamma parameter controls how far the influence of a single training example reaches, with low values meaning far and high values meaning close. The cost parameter controls training errors and margins. A small cost creates a large margin (a soft margin) and is more tolerant of misclassifications.
GBM model has several benefits as well. First, GBM, as a type of ensemble model, is usually not susceptible to overfitting. It is very easy for other models to overfit the training data given the small size of the dataset. Second, it also uses a technique called boosting, which aggregates multiple weak learners into stronger ones. It builds on the weak model – decision tree, and optimizes it in a stage-wise fashion using a differential loss function. However, there are also weaknesses. First, it is sensitive to outliers. Because each weak classifier is committed to fix its predecessors’ shortcomings, the model might pay too much attention to outliers. Second, it is slower to train compared to models using bagging, such as random forest. For hyper-parameter tuning, the interaction depth is the maximum number of nodes per tree. We set three values for it – 3, 5, 8, because 5 is the most commonly used number in practice. Any number greater than 8 is prone to overfitting. The shrinkage is the learning rate and is used for reducing, or shrinking, the impact of each additional fitted tree. We want to find the right value for learning rate so that the model converges within a reasonable time. ` n.minobsinnode` is the minimum number of observations in trees' terminal nodes. We also want to find the right number so that we neither overfit nor underfit.   

In summary, each model has its pros and cons. Many other models could be potential alternatives. These include random forest, logistic regression, and KNN. However, due to our limited space, we only used the three models that we think are best suited for the dataset. The insights these models provide will be covered in the evaluation section.

The business goal of the model is to reduce the attrition rate of the company. While maximizing the accuracy of the model, we also want to compare different models’ precision rate — how often is the model right when an instance of attrition is predicted, as well as sensitivity rate — how good is the model at identifying attrition. CT, SVM, and GBM show accuracy rates of 82.9%, 84.0%, and 81.6%, respectively. According to the ROC curves generated from each model, the AUCs of decision tree model, SVM model, and GBM model are 63.1%, 57.1%, and 71.4% respectively. Because of the imbalanced nature of the dataset, SVM model predicts all results to be negative. The accuracy rates are not very different; decision tree model shows better precision and GBM model shows a better sensitivity rate. The decision tree model is easier to understand for managers, and it gives specific demarcation lines. For example, people whose monthly income is lower than $3,485, who don’t have work overtime, and who are younger than 31 years old have a 5% probability of leaving the company. 

### 4)	Evaluation
Our evaluation methods include temporal splits, cross validation, and domain knowledge validation. Because the data is imbalanced, we did a stratified random split of the data, 80% for training and 20% for testing. Cross validation was also performed on all three models. For example, in the decision tree model, we did a 5-fold cross validation and we found the training accuracy to be 88.2% and testing accuracy to be 82.9%, which means the model is not over-fitting and shows relatively good generalization. According to the results of the decision tree model, overtime, total working years, and monthly income are the top three influential factors of attrition, which is comprehensible from the standpoint of a modeler. The GBM model indicates income, age, and overtime to be the most influential factors, which are very close to the results of the CT model.
According to Employee Benefit News (EBN), it costs employers 33% of a worker's annual salary to hire a replacement if that worker leaves. In dollar figures, the replacement cost is $15,000 per person for an employee earning a median salary of $45,000 a year. Work Institute’s 2017 Retention Report shows that study of 34,000 respondents concluded that 75% of the causes of employee turnover are preventable. (Valerie Bolden-Barrett, 2017) The decision tree model is very easy to understand for most managers, and it can help reducing the attrition rate of the talents in the company by providing more information about the employees that has not been revealed or noticed by the management. The input for this model is very easy to collect: overtime, total working years, monthly income, employee age, job role, environment satisfaction, etc. The management can use the model for prediction of employee turnover after inputting the information of each employee and making adjustments or remedies if someone is very likely to leave. At the same time, the management can use the tree model as a benchmark for determining employees’ salary, overtime, or benefits.

### 5)	Deployment
Due to the extreme unbalance of the original dataset, only a few people who choose to quit their job in IMB, this makes all the models have high accuracy and low sensitivity. The models are predicting that most employees will stay, and few will quit. When a model like this is deployed in the real world, it will classify people who will actually quit the job as staying. Notice that our model provided an option to use over sample technique to fix this problem. This method will enlarge the "attrition" data and bring it to the same level with "not attrition." Thus, the model will have better sensitivity. The scores calculated before, however, come from models trained and tested on the original data, instead of the oversampled data. For now, the deployment analysis will be based on a model that cannot correctly predict the probability of attrition. 

The model can be deployed to the human resource department of IBM, with some more modification, the model will be fit more companies across many different industries. The original purpose of this model is to predict how an employee will quit the job during his career. It could be helpful for the firm to make hiring. For example, the model is capable of predicting how likely a candidate will quit the job base on his or her resume. If he or she is highly like to leave in a short period, HR will pay extra attention to this candidate during the interview, possibly ask some questions about the desired career path and plan. There is another way to use this model, as well. The tree model can be used backward. Consider a valuable employee is about to quit his job, and as the head of the human resource department, you do not want him to leave. The model will be able to tell what factors caused him to leave by plugging this employee's information into the model. Once they find where the problem is and fix this problem, the company will have a higher chance persuading this person to stay in the firm.

On the other hand, the model can potentially bring some issues to the firm. As mentioned above, the model can predict how likely a person will quit the job even before he or she joins the company; the model could be misleading. Knowing how likely a candidate will quit in the future is essential, but it cannot be a sole determining factor when making the hiring choice. The HR department should now rely solely on this model but should use their judgment in addition to the model. Results from the model could only be used as a reference. Furthermore, for-profit companies will only hire a new employee if the firm believes that this new employee can bring benefits to the firm, even though he or she will not stay for an extended period.

In addition, there are some major ethical concerns because the using factors such as gender and age in most jurisdictions violates labor laws and might entail legal issues. GBM model, for example, produces a bar graph of relative influence for all variables, which is shown below.

The factors on the top are variables that affect attrition the most. Most of them lead to no ethical problem. For example, when work overtime is high, the attrition is high. When monthly income is high, the attrition is low. The higher the environment satisfaction, the lower the attrition. The higher the job satisfaction, the lower the attrition. These variables make perfect sense, and they are playing an important role in the model. This means the majority of the model will not cause ethical issues. However, there are still some minor issues in the model that could cause ethical problems. It looks like the employee’s gender has some minor differences in influence within the model. Therefore, we suggest that companies cautiously use the model. To mitigate potential risks of hiring caused by this model, the best practice is to always put the predicted result behind human judgment.

## References
- Bolden-Barrett, V. (2017, August 11). Study: Turnover costs employers $15,000 per worker. Retrieved May 11, 2020, from https://www.hrdive.com/news/study-turnover-costs-employers-15000-per-worker/449142/
- https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset
